{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train/Green: 100%|██████████| 668/668 [00:03<00:00, 210.64it/s]\n",
      "Processing train/Green_Yellow: 100%|██████████| 348/348 [00:01<00:00, 212.28it/s]\n",
      "Processing train/Yellow: 100%|██████████| 363/363 [00:01<00:00, 204.65it/s]\n",
      "Processing test/Green: 100%|██████████| 135/135 [00:00<00:00, 189.81it/s]\n",
      "Processing test/Green_Yellow: 100%|██████████| 81/81 [00:00<00:00, 224.43it/s]\n",
      "Processing test/Yellow: 100%|██████████| 80/80 [00:00<00:00, 234.01it/s]\n",
      "Processing val/Green: 100%|██████████| 137/137 [00:00<00:00, 224.59it/s]\n",
      "Processing val/Green_Yellow: 100%|██████████| 82/82 [00:00<00:00, 234.97it/s]\n",
      "Processing val/Yellow: 100%|██████████| 79/79 [00:00<00:00, 236.72it/s]\n",
      "C:\\Users\\Kenan\\AppData\\Local\\Temp\\ipykernel_24848\\799617005.py:67: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[feature_cols] = pd.DataFrame(df['features'].tolist(), index=df.index)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset saved to ripeness_dataset2.csv with 1973 entries\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "\n",
    "def extract_features(image_path):\n",
    "    \"\"\"Extract color and texture features from an image\"\"\"\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.resize(img, (128, 128))  # Resize for consistency\n",
    "    \n",
    "    features = []\n",
    "    \n",
    "    # Color features (RGB and HSV histograms)\n",
    "    for channel in range(3):\n",
    "        hist = cv2.calcHist([img], [channel], None, [16], [0, 256])\n",
    "        features.extend(hist.flatten())\n",
    "        \n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    for channel in range(3):\n",
    "        hist = cv2.calcHist([hsv], [channel], None, [16], [0, 256])\n",
    "        features.extend(hist.flatten())\n",
    "    \n",
    "    # Texture features (GLCM)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    glcm = graycomatrix(gray, distances=[1], angles=[0], levels=256, symmetric=True, normed=True)\n",
    "    texture_features = [\n",
    "        graycoprops(glcm, 'contrast').item(),\n",
    "        graycoprops(glcm, 'energy').item(),\n",
    "        graycoprops(glcm, 'homogeneity').item(),\n",
    "        graycoprops(glcm, 'correlation').item()\n",
    "    ]\n",
    "    features.extend(texture_features)\n",
    "    \n",
    "    return features\n",
    "\n",
    "def create_dataset_csv(root_dir, output_csv):\n",
    "    \"\"\"Convert image directory structure to CSV\"\"\"\n",
    "    rows = []\n",
    "    \n",
    "    splits = ['train', 'test', 'val']\n",
    "    classes = ['Green', 'Green_Yellow', 'Yellow']\n",
    "    \n",
    "    for split in splits:\n",
    "        split_path = os.path.join(root_dir, split, 'img')\n",
    "        for cls in classes:\n",
    "            class_path = os.path.join(split_path, cls)\n",
    "            for img_name in tqdm(os.listdir(class_path), desc=f\"Processing {split}/{cls}\"):\n",
    "                img_path = os.path.join(class_path, img_name)\n",
    "                try:\n",
    "                    features = extract_features(img_path)\n",
    "                    rows.append({\n",
    "                        'split': split,\n",
    "                        'label': cls,\n",
    "                        'features': features,\n",
    "                        'image_path': img_path\n",
    "                    })\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {img_path}: {str(e)}\")\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(rows)\n",
    "    \n",
    "    # Expand features into separate columns\n",
    "    feature_cols = [f'feature_{i}' for i in range(len(features))]\n",
    "    df[feature_cols] = pd.DataFrame(df['features'].tolist(), index=df.index)\n",
    "    df.drop(columns=['features'], inplace=True)\n",
    "    \n",
    "    # Save to CSV\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"Dataset saved to {output_csv} with {len(df)} entries\")\n",
    "\n",
    "# Usage\n",
    "create_dataset_csv('ripeness', 'ripeness_dataset2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NvidiaEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
